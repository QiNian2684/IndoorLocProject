# 室内定位系统综合指南

本综合指南提供了如何运行室内定位系统、配置参数、优化模型、解读结果以及解决常见问题的详细说明。该系统基于 UJIIndoorLoc 数据集，将支持向量回归（SVR）与 Transformer 架构相结合，实现高精度的室内定位。

------

## 目录

1. [系统概述](https://o1.g888.ai/c/681b5261-05c8-8003-b9a2-c2fdcc0de3d9#系统概述)
2. [代码运行](https://o1.g888.ai/c/681b5261-05c8-8003-b9a2-c2fdcc0de3d9#代码运行)
3. [参数配置](https://o1.g888.ai/c/681b5261-05c8-8003-b9a2-c2fdcc0de3d9#参数配置)
4. [模型优化](https://o1.g888.ai/c/681b5261-05c8-8003-b9a2-c2fdcc0de3d9#模型优化)
5. [结果解读](https://o1.g888.ai/c/681b5261-05c8-8003-b9a2-c2fdcc0de3d9#结果解读)
6. [架构分析](https://o1.g888.ai/c/681b5261-05c8-8003-b9a2-c2fdcc0de3d9#架构分析)
7. [优化流程](https://o1.g888.ai/c/681b5261-05c8-8003-b9a2-c2fdcc0de3d9#优化流程)
8. [故障排查](https://o1.g888.ai/c/681b5261-05c8-8003-b9a2-c2fdcc0de3d9#故障排查)

------

## 系统概述

### 系统功能与目标

该室内定位系统旨在利用 WiFi 指纹技术来估计用户在建筑物内部的位置。WiFi 指纹技术通过获取多个无线接入点（WAPs）的接收信号强度指示（RSSI），在无需额外硬件或修改基础设施的情况下，为用户提供位置信息。

该系统主要面向 GPS 信号通常不可用的室内复杂环境，并能在以下应用场景发挥关键作用：

- 商场、医院、机场等复杂建筑环境中的导航
- 大型场所的资产追踪和管理
- 多层建筑中的应急响应协调
- 室内空间中的基于位置的服务与分析

### 核心特性与功能

#### 多模型集成方法

系统提供了三种将传统机器学习与深度学习相结合的方式：

- **特征提取模式（Feature Extraction Mode）**
   在此模式下，Transformer 神经网络充当高级特征提取器，先对高维 WiFi 信号数据进行处理，提取出更具意义的特征表示，再将该表示输入 SVR 模型以完成最终的坐标预测。该架构利用 Transformer 对输入数据中复杂关系的捕捉能力，并结合 SVR 在回归任务上的泛化能力。
- **集成模式（Ensemble Mode）**
   此模式中，两个模型分别使用相同的输入数据进行独立训练，各自输出定位预测，然后通过加权平均将两者的预测结果结合成最终输出。该方法可发挥两个模型的互补优势，从而提升整体稳定性和精度。
- **端到端模式（End-to-End Mode）**
   在这一高级配置下，SVR 和 Transformer 共同组成一个单一的统一架构，并进行联合训练。系统在深度学习框架内融入了 SVR 的损失函数，使各组件间的信息能够无缝流动，并实现对整个管线的联合优化。

#### 双任务预测

系统针对室内定位的两个基本方面进行预测：

- **楼层分类（Floor Classification）**
   判断用户在多层建筑的哪一层楼。本质上是一个分类任务，系统输出离散的楼层号。
- **坐标预测（Coordinate Prediction）**
   预测用户在相应楼层上的精确二维坐标（经度和纬度）。这是一个回归任务，系统输出连续坐标值。

#### 自适应反馈机制

系统引入了创新的双层反馈系统来持续提升定位精度：

- **底层反馈（Lower-Level Feedback）**
   该机制基于近期定位误差对模型输出做即时调整，快速适应局部空间环境的特征。
- **高层反馈（Higher-Level Feedback，元自适应）**
   这一高级组件通过长期误差记录来分析误差模式，并对底层学习参数做战略性调整，以修正系统性偏差或适应环境变化。

#### 自动化参数优化

系统集成了超参数优化框架 Optuna，具有以下功能：

- 高效探索可能的模型配置空间
- 利用早期淘汰机制（Pruning）尽早排除表现不佳的参数组合
- 提供参数重要性分析和可视化
- 支持针对不同计算预算的多种搜索空间配置

#### 全面评估

系统提供广泛的评估功能：

- 多种准确性度量指标（平均误差、中位数误差、楼层准确率等）
- 适用于误差分析的可视化工具（CDF 曲线、误差分布、二维散点图）
- 针对室内定位的空间交叉验证方法，确保评估的真实性
- 系统比较工具，可对各种配置的定位精度进行系统化的对比试验

### 主要组件

系统由若干相互关联的模块构成，每个模块负责室内定位过程中的特定环节：

#### 数据处理模块

- **Loader（`loader.py`）**
   负责下载并加载 UJIIndoorLoc 数据集，提供便捷的训练与验证数据访问接口。
- **Preprocessor（`preprocessor.py`）**
   将原始 WiFi 信号数据转换为适合机器学习的格式，包括缺失值处理、归一化，以及可选的降维操作。
- **Feature Engineering（`feature_engineering.py`）**
   实现多种特征提取技术，如 PCA 和基于 Transformer 的特征提取。

#### 模型架构模块

- **Base Models（`base.py`）**
   定义定位模型的抽象基类和接口，保证不同模型实现的一致性。
- **SVR Models（`svr_model.py`）**
   实现用于坐标预测的支持向量回归模型，支持多种核函数及配置。
- **Transformer Models（`transformer_model.py`）**
   实现基于 Transformer 的神经网络架构，用于深度学习定位任务。
- **Hybrid Models（`hybrid_model.py`）**
   采用三种集成策略（特征提取、集成、端到端）将 SVR 与 Transformer 方法相结合。
- **Floor Models（`floor_model.py`）**
   实现楼层分类模型，支持随机森林（Random Forest）、SVM 和 XGBoost 等不同选项。

#### 反馈机制模块

- **Base Feedback（`base_feedback.py`）**
   定义了在定位系统中实现反馈回路的基础类。
- **Dual-Layer Feedback（`dual_layer_feedback.py`）**
   实现双层自适应反馈系统，包括即时调整的底层反馈和带有元学习能力的高层反馈机制。

#### 评估与可视化模块

- **Metrics（`metrics.py`）**
   实现多种定位精度评价指标，包括欧几里得距离误差、楼层预测准确率以及基于百分位的度量。
- **Visualization（`visualization.py`）**
   提供多种工具，用于创建模型性能与误差特征的可视化图表。
- **Cross-Validation（`cross_validation.py`）**
   实现空间和分层（层次式）交叉验证策略，尊重定位数据在空间上的分布特性。

#### 优化与实验模块

- **Optuna Optimizer（`optuna_optimizer.py`）**
   利用 Optuna 实现超参数优化框架，支持多种搜索空间和优化目标。
- **Search Spaces（`search_spaces.py`）**
   定义不同规模与重点的参数搜索空间，适用于轻量测试到全面优化等不同需求。
- **Training Monitor（`monitor.py`）**
   监控训练过程，记录相关指标并生成训练过程的可视化图表。

------

## 代码运行

### 环境配置

在运行系统之前，请确保您的环境已正确安装了所需的依赖包。系统主要依赖多个 Python 库：

```bash
# 核心依赖
pip install numpy pandas scikit-learn torch matplotlib seaborn optuna

# 可选依赖
pip install xgboost  # 若需使用 XGBoost 进行楼层分类，需要安装该库
```

若要获得最优性能，推荐使用支持 CUDA 的 GPU，尤其是在训练大规模 Transformer 模型时。但若在纯 CPU 环境下使用，也可通过调整相关配置进行运行。

### 基本执行命令

系统提供了两个主要的执行入口，分别满足不同的需求：

```bash
# 单一实验（使用一组配置）
python main.py

# 在多组配置间进行比较性实验
python run_experiments.py --experiment all
```

- `main.py` 脚本用于单次实验，可使用 `config.py` 中的默认参数，或通过命令行参数覆盖默认配置。该脚本会完成数据加载、预处理、模型训练、评估和结果保存的所有步骤。
- `run_experiments.py` 脚本可按照预先设定的方案进行多组实验，以对比不同配置在定位精度上的差异，并进行系统化的比较。

### 命令行选项详解

#### `main.py` 的选项

通过命令行参数可覆盖 `config.py` 中的配置，而无需直接修改文件内容：

```bash
# 集成方式选择
python main.py --integration_type feature_extraction
```

指定将 SVR 与 Transformer 模型结合的模式，选项包括：

- `feature_extraction`：利用 Transformer 做特征提取，再交由 SVR 回归
- `ensemble`：分别训练两个模型并加权组合预测
- `end2end`：将二者整合为统一架构共同训练

```bash
# 反馈机制启用控制
python main.py --with_feedback
python main.py --without_feedback
```

用以开启或关闭双层反馈机制。开启后，模型会根据近期和长期误差进行自适应学习，从而不断提升定位精度。

```bash
# 超参数优化设置
python main.py --no_optimization
python main.py --n_trials 200
```

- `--no_optimization`：跳过超参数优化，直接使用 `config.py` 中的默认参数。
- `--n_trials 200`：在超参数优化时设置最大试验次数为 200。试验次数越多，通常能找到更优的参数组合，但计算量也会增加。

```bash
# 随机数种子控制
python main.py --random_state 42
```

设置固定的随机数种子以确保结果的可复现性。该种子会影响模型训练的初始化、数据拆分以及优化过程中的随机操作。

```bash
# 自定义实验名称
python main.py --experiment_name my_custom_experiment
```

允许为实验目录指定自定义名称，便于区分不同运行产生的结果。

```bash
# 组合使用多个选项
python main.py --integration_type ensemble --with_feedback --n_trials 50 --random_state 42
```

可以灵活组合多个选项，以精细地控制实验配置。

#### `run_experiments.py` 的选项

`run_experiments.py` 用于系统地比较不同配置，可使用以下命令行选项：

```bash
# 选择对比实验类型
python run_experiments.py --experiment integration
```

可选项：

- `integration`：比较不同集成方式（feature_extraction、ensemble、end2end）
- `feedback`：比较是否启用反馈机制对系统性能的影响
- `optimization`：比较不同超参数优化规模的效果
- `all`：依次运行上述三种对比实验

```bash
# 控制实验间的暂停时间
python run_experiments.py --sleep 120
```

在连续实验之间添加指定秒数的延时，可在使用 GPU 资源时让系统稍作缓冲。

```bash
# 自定义整体对比实验的标识符
python run_experiments.py --run_id custom_identifier
```

为整组对比实验提供一个唯一标识，便于后续跟踪分析结果。

### 计算设备配置

系统会自动检测并利用可用的 GPU 资源来加速训练，尤其适合规模较大的 Transformer 模型。在启动时，系统会显示当前使用的计算设备信息，例如：

```
==================================================
Using computing device: cuda (NVIDIA RTX 3080)
==================================================
```

若需要在有 GPU 的环境中强制只使用 CPU（如调试、资源管理等），可在 `config.py` 中修改相关参数：

```python
MODEL_CONFIG = {
    'device': 'cpu',  # 将 'cuda' 改为 'cpu' 即可强制使用 CPU
    # 其他设置...
}
```

在以下场景下尤其适合强制使用 CPU：

- 调试与定位内存相关的问题
- 在共享 GPU 环境下并行运行多个实验
- 处理超大模型时，GPU 显存可能不足
- 测试在 CPU 环境下的部署流程

------

## 参数配置

系统通过 `config.py` 中的各类配置参数来控制具体行为。本节将详细介绍各配置项的含义、推荐取值、对系统性能的影响以及使用注意事项。

### 数据配置

`DATA_CONFIG` 区域控制数据加载、预处理和特征工程流程：

```python
DATA_CONFIG = {
    'data_dir': './data/raw',         # 数据存放路径
    'download': True,                 # 若无数据文件，是否自动下载
    'replace_value': -105,            # 对未检测到信号（原始值为100）使用的替代强度值
    'normalization': 'minmax',        # 归一化方法: 'minmax'|'standard'|'robust'|None
    'dimension_reduction': 'pca',     # 降维方式: 'pca'|None
    'n_components': 50,               # PCA 保留的主成分个数
    'test_size': 0.2,                 # 若无单独验证集，则从训练集中切分的测试比例
}
```

#### 参数详解

**`data_dir`**：数据文件存放或查找的目录路径

- 系统会在此目录下寻找 `TrainingData.csv` 和 `ValidationData.csv`。
- 可使用相对路径或绝对路径。
- 请确保该目录有足够的存储空间（约 20MB）。

**`download`**：是否自动下载数据集

- 为 `True` 时，若本地不存在 UJIIndoorLoc 数据集，系统会自动下载。
- 若在无网络或需自行下载的环境，可将其设为 `False`。
- 下载完成后会自动解压并放置到相应目录结构中。

**`replace_value`**：对未检测到信号的 WAP 填充值（dBm）

- 原始数据用 `100` 表示未检测到信号，这并非有效的 RSSI 值。
- 常用的最低可检测信号强度在 -105 ~ -110 dBm 之间，做统一替换较为合理。
- 取值过高会让模型对这些“缺失”信号过分关注，取值过低又会与真实的弱信号混淆。

**`normalization`**：特征归一化方法

- `minmax`：将数值缩放到 [0,1] 区间，保留相对差异，常见通用选择。
- `standard`：标准化到均值为 0、标准差为 1，在特征量级差异较大时效果好。
- `robust`：基于分位数的缩放，对异常值不敏感。
- `None`：不做任何归一化，通常仅在算法对尺度不敏感时使用。

**`dimension_reduction`**：降维方式

- `pca`：使用主成分分析以保留主要的数据信息。
- `None`：不做降维，保留全部 520 个原始 WAP 特征。
- 降维可有效减少噪声和冗余，从而加快训练并可能提升模型效果。

**`n_components`**：PCA 保留的主成分数

- 仅在 `dimension_reduction='pca'` 时生效。
- 该值在 30~100 之间较为常见，50 是个折中选择。
- 应确保在该主成分数下保留至少 90% 的原始数据方差。

**`test_size`**：训练集拆分出测试集的比例

- 用于未提供单独验证集时的场景。
- 一般取值在 0.1~0.3 范围，默认 0.2（20%）较为常见。
- 测试集过小会降低评估可靠性，过大又会减少训练数据量。

### 模型配置

`MODEL_CONFIG` 部分包含多个子区域，分别控制模型训练的不同层面。

#### 通用设置与早停策略

```python
MODEL_CONFIG = {
    'device': 'cuda',  # 计算设备: 'cuda'|'cpu'

    'early_stopping': {
        'enabled': True,                  # 是否启用早停
        'patience': 15,                   # 验证指标无显著提升的容忍轮数
        'min_delta': 0.0001,              # 判断“提升”时的最小变化
        'verbose': True,                  # 是否打印早停信息
        'mode': 'min'                     # 'min' 适用于损失, 'max' 适用于准确率等
    },
    # 其他配置...
}
```

**`device`**：指定训练和推理使用的计算设备

- `cuda`：使用 GPU 进行加速（需要支持 CUDA 的 GPU 和对应的 PyTorch）。
- `cpu`：仅使用 CPU 进行计算。
- 在大多数深度学习场景中，GPU 通常可带来 5~20 倍的速度提升。
- CPU 模式适合小规模调试或资源受限的环境。

**早停（Early Stopping）参数**：

- **`enabled`**：是否激活早停机制。
  - 启用后，如果验证集指标在若干轮内未改善，就会提前停止训练。
  - 可有效节省训练时间，并防止过拟合。
- **`patience`**：在验证指标没有提升的情况下继续训练的轮数。
  - 一般取值 5~30。
  - 值过低可能导致过早停止，过高会浪费计算资源。
- **`min_delta`**：判定指标是否“提升”的最小差值。
  - 值越小越敏感，常取 0.0001~0.001。
  - 有助于滤除指标中的微小随机波动。
- **`verbose`**：是否打印早停状态消息。
  - 打开后可及时了解训练何时以及为何停止。
- **`mode`**：指标优化方向
  - `min`：用于越低越好的指标（如损失、误差）。
  - `max`：用于越高越好的指标（如准确率）。

#### SVR 模型参数

```python
'svr': {
    'kernel': 'rbf',   # 核函数: 'linear'|'rbf'|'poly'|'sigmoid'
    'C': 10.0,         # 正则化参数
    'epsilon': 0.1,    # ε 不敏感损失带宽度
    'gamma': 'scale',  # 核系数: 'scale'|'auto'|浮点数
    'degree': 3,       # 多项式核的阶数
    'cache_size': 1000 # 计算用的缓存大小（MB）
}
```

**`kernel`**：SVR 使用的核函数类型

- `linear`：线性核，仅能捕捉线性关系，速度快但表达能力有限。
- `rbf`：高斯核（径向基核），适合大多数非线性场景，室内定位中常见优选。
- `poly`：多项式核，适合特定多项式关系，但通常训练较慢。
- `sigmoid`：类似于单隐层神经网络的激活函数，实际应用中较少见。
- 对室内定位问题而言，`rbf` 核通常表现最佳。

**`C`**：正则化参数

- 值越大（10~100），模型对训练数据的拟合越充分，但可能过拟合。
- 值越小（0.1~1），则正则化更强，模型更简单但可能欠拟合。
- 在室内定位中通常取值 1~10，10 是常见的默认起点。

**`epsilon`**：ε 不敏感损失带参数

- 较小值（0.01~0.1）对精度要求更高，支持向量更多，训练更慢但精度更高。
- 较大值（0.1~1.0）对误差更宽容，支持向量较少，训练更快但精度可能降低。
- 对于室内定位的米级精度，0.1 是较合适的起始点。

**`gamma`**：对于 `rbf`、`poly`、`sigmoid` 核而言的核系数

- 控制单个训练样本对决策边界的影响范围。
- `scale`：自动计算为 1 / (特征数 * 样本方差)，通常是较优的默认值。
- `auto`：自动计算为 1 / 特征数，对数据尺度不敏感。
- 显式浮点数：小值（0.001~~0.1）对应更宽松的影响范围，大值（1~~10）对应更局部化的影响。
- 设置不当的 gamma 值会导致模型严重欠拟合或过拟合。

**`degree`**：多项式核的阶数

- 仅在 `kernel='poly'` 时生效。
- 一般取值 2~5。阶数越高，能表示的关系越复杂，但也更易过拟合。

**`cache_size`**：核函数计算时的缓存大小（MB）

- 对大数据集的训练性能影响明显。
- 适度增大可显著加速训练，但需保证内存充足。
- 对 UJIIndoorLoc 而言，1000MB（1GB）通常足够。

#### Transformer 模型参数

```python
'transformer': {
    'input_dim': 520,      # 输入维度（WAP 数量或降维后特征维度）
    'd_model': 256,        # 模型隐向量维度
    'nhead': 8,            # 多头注意力的头数（须整除 d_model）
    'num_layers': 4,       # 编码器层数
    'dim_feedforward': 512,# 前馈网络维度
    'dropout': 0.1,        # Dropout 概率
    'output_dim': 2,       # 输出维度（经度和纬度）
    'batch_size': 64,      # 训练批大小
    'epochs': 100,         # 最大训练轮数
    'lr': 0.001            # 学习率
}
```

**`input_dim`**：输入数据的维度

- 若使用原始 WiFi 特征，则为 520。
- 若进行了降维，则应与 `n_components` 相同。
- 与实际输入特征不一致会导致运行错误。

**`d_model`**：Transformer 的内部表示维度

- 决定注意力机制的大小以及模型容量。
- 大（256~512）表示更强的建模能力，但计算量更大，易过拟合。
- 小（64~128）训练更快，更省内存，但特征表达能力有限。
- 室内定位中，256 是兼顾效果与代价的常用选择。
- 注意 `d_model` 必须能被 `nhead` 整除。

**`nhead`**：多头注意力的头数

- 多头允许模型并行关注输入的不同部分。
- 通常取值为 4 或 8，但需能整除 `d_model`。
- 头数越多，学习到的模式越多样，但计算开销也增大。
- 对 WiFi 定位而言，`nhead=8` 配合 `d_model=256` 常见。

**`num_layers`**：Transformer 编码器的层数

- 层数越多，模型越深，能学习更复杂的模式，但更难训练。
- 浅层（2~3 层）训练更快，也更不易过拟合。
- 对 UJIIndoorLoc，4 层一般是不错的平衡点。
- 超过 6 层的网络增益往往有限，但耗时会明显增多。

**`dim_feedforward`**：Transformer 中前馈网络的维度

- 通常为 `d_model` 的 2~4 倍。
- 值越大，非线性变换能力越强，但计算量和显存占用也越高。
- 当 `d_model=256` 时，512~1024 较为常见。

**`dropout`**：Dropout 概率

- 防止过拟合的常用手段。
- 一般取 0.1~0.3。
- 如果模型过拟合，可适当提高；若学习困难，可适当降低。

**`output_dim`**：模型输出维度

- 二维坐标预测时取 2（经度、纬度）。
- 若考虑三维定位，可取 3（包含楼层或高度的连续值）。

**`batch_size`**：训练时的批大小

- 大批大小（64~128）会使梯度估计更稳定，也会更快收敛。
- 小批大小（16~32）可能有更好的泛化能力且显存占用更低。
- 若遇到显存不足问题，可减少此值。
- 64 是大多数环境下的常见起始点。

**`epochs`**：最大训练轮数

- 轮数越多，模型拥有更多学习机会，但训练时间也越长。
- 通常会配合早停策略，不一定需要跑满所有轮数。
- 对大多数场景，100 轮足以满足收敛需求。

**`lr`**：学习率

- 控制权重更新的步幅大小。
- 典型取值在 0.0001~0.001 之间。
- 过大会导致训练不稳定甚至发散，过小则收敛缓慢。
- 0.001 是一个常见的默认起点，后续可根据训练过程进行微调。

#### 混合模型配置

```python
'hybrid': {
    'integration_type': 'feature_extraction',  # 'feature_extraction'|'ensemble'|'end2end'
    'weights': {'svr': 0.5, 'transformer': 0.5}  # 用于集成模式的权重
}
```

**`integration_type`**：指定 SVR 与 Transformer 的结合方式

- `feature_extraction`：Transformer 作为特征提取器，再由 SVR 进行回归。
  - 优点：同时利用 Transformer's 表达学习和 SVR 的回归能力；相对训练简单。
  - 缺点：特征提取过程可能损失部分信息；两部分不做端到端联合优化。
  - 适用场景：中等规模数据、计算资源相对有限的环境。
- `ensemble`：独立训练并加权平均预测结果。
  - 优点：充分利用两个模型的互补优势，一般精度最高。
  - 缺点：需要同时维护并训练两套完整模型，推理速度也相对慢。
  - 适用场景：对精度要求极高，计算资源允许的场合。
- `end2end`：将两者整合为单一架构，进行联合训练。
  - 优点：可实现信息无缝交互，理论上能学到最佳集成方式。
  - 缺点：训练较为复杂，需要更多数据与调参时间。
  - 适用场景：拥有大量数据、对精度要求极高且有足够调参精力的环境。

**`weights`**：在 `ensemble` 模式下的加权参数

- 仅在 `integration_type='ensemble'` 时生效。
- `svr`：SVR 预测结果的权重；`transformer`：Transformer 预测结果的权重。
- 两者权重之和应为 1.0。
- 初始可设为 0.5 : 0.5，再根据模型单独表现微调。
- 若某一模型 consistently 优于另一模型，可适当提高其权重。

#### 反馈机制配置

```python
'feedback': {
    'enabled': True,          # 是否启用反馈
    'learning_rate': 0.01,    # 底层反馈的学习率
    'meta_learning_rate': 0.001, # 高层反馈的元学习率
    'feedback_window': 100    # 高层反馈所查看的误差窗口大小
}
```

**`enabled`**：控制是否激活双层反馈机制

- 若为 True，系统可根据定位误差实现自适应调整，尤其适用于环境变化、存在系统偏差的场景。
- 若仅需做基线测试，可设为 False。

**`learning_rate`**：底层（即时）反馈的学习率

- 控制模型对近期误差的响应速度。
- 过大（0.1 以上）可能使模型不稳定，过小（0.001 以下）则适应较慢。
- 0.01 通常兼顾适应性与稳定性。

**`meta_learning_rate`**：高层（元自适应）反馈的学习率

- 用于调整底层学习速率等关键参数。
- 一般比底层学习率更小（通常小 10 倍）。
- 过高可能导致元自适应不稳定，0.001 是较为保守的默认值。

**`feedback_window`**：高层反馈计算时的误差窗口大小

- 决定高层反馈所参考的历史定位结果数目。
- 数值越大（100~500），更平滑稳定，但适应变化更慢。
- 数值越小（20~50），适应更快，但更易受短期异常波动影响。
- 100 是大多数环境下的良好起点。

#### 楼层分类配置

```python
'floor_classifier': {
    'type': 'random_forest',  # 'random_forest'|'svm'|'xgboost'
    'n_estimators': 100,      # 随机森林或 XGBoost 的树数
    'max_depth': None,        # 树的最大深度（None 表示不限制）
    'min_samples_split': 2,   # 节点再分裂所需的最小样本数
    'min_samples_leaf': 1     # 叶节点所需的最小样本数
}
```

**`type`**：楼层分类器类型

- `random_forest`：基于多棵决策树的随机森林，兼具准确度、速度和稳定性。
- `svm`：支持向量机分类器，对高维数据有利，但在大规模数据下速度偏慢。
- `xgboost`：梯度提升树，在很多场景下精度较高，但需要安装 xgboost 包。
- 对大多数场景而言，`random_forest` 是一个性能和训练速度都较优的默认选择。

**`n_estimators`**：树的数量（针对 `random_forest` 和 `xgboost`）

- 数量越多（100~500），模型越稳健但训练时间也更长。
- 数量较少（10~50）训练更快，但泛化能力可能较弱。
- 通常 100~200 就能获得不错的效果，继续增大会有递减回报。

**`max_depth`**：决策树的最大深度

- `None` 表示不做限制，会一直分裂至叶节点纯净或达到其他停止条件。
- 显式数值可防止过拟合，典型取值 10~50。
- 对大数据集可允许更深的树，对小数据集需防止过拟合。

**`min_samples_split`**：节点再分裂所需的最小样本数

- 取值越高（5~10），树越“粗”且泛化更好，但可能欠拟合。
- 取值越低（2~3），树越“细”且拟合更精细，但可能过拟合。
- 默认 2 是最常见的选择。

**`min_samples_leaf`**：叶节点所需的最小样本数

- 和 `min_samples_split` 类似，越大越能防止过拟合。
- 取值 5~10 可以提升模型稳定性，但精细度会下降。
- 1~3 时模型能捕捉更多细节，对噪声敏感度也随之升高。

### 优化配置

`OPTIMIZATION_CONFIG` 区域控制超参数优化流程：

```python
OPTIMIZATION_CONFIG = {
    'n_trials': 500,          # Optuna 试验次数
    'timeout': None,          # 超时时间（秒），None 表示无时限
    'n_jobs': 1,              # 并行作业数
    'direction': 'minimize',  # 优化方向：'minimize'（误差）、'maximize'（准确率）
    'cv': 5,                  # 交叉验证折数
    'cv_method': 'spatial',   # 交叉验证方式：'spatial'|'random'|'hierarchical'
    'search_space': 'default' # 搜索空间类型：'default'|'light'|'comprehensive' 等
}
```

**`n_trials`**：在超参数优化中要尝试的参数组合数

- 试验次数越多（200~1000），搜索越全面，效果越好，但耗时更长。
- 试验次数较少（30~100）搜索速度快，但可能找不到最优配置。
- 通常 500 足以在大多数场景中获得不错结果。
- 初步试验可取 50~100 以探索大致范围。

**`timeout`**：优化过程的最大时间限制（秒）

- `None` 表示不设时限。
- 也可设为如 3600（1 小时）等限制，以防单次优化占用过多时间。
- 当 `n_trials` 和 `timeout` 同时存在时，会在任何一项先到达时终止。

**`n_jobs`**：并行执行的进程数

- `1` 表示顺序执行所有试验。
- 大于 1 时，可并行执行多个试验以加速搜索。
- 并行数不应超过实际 CPU 核心数。
- 对计算量较大的 SVR 或 Transformer，开启并行可显著缩短整体搜索时间，但会增加内存占用。

**`direction`**：优化目标

- `minimize`：适合误差、损失等指标越低越好。
- `maximize`：适合准确率、F1 等指标越高越好。
- 室内定位中通常以误差最小为主。

**`cv`**：交叉验证的折数

- 数值越大（5~10），评估更可靠，但训练开销也更大。
- 数值较小（3），运行更快，但评估方差更高。
- 大多数情况下，5 折是平衡度较好的选择。

**`cv_method`**：交叉验证的方式

- `spatial`：基于空间位置拆分数据，确保验证集中与训练集中在空间上不重叠，更真实地反映定位效果。
- `random`：常规随机拆分，不考虑空间分布。
- `hierarchical`：按照建筑和楼层层次进行拆分。
- 对室内定位任务，`spatial` 通常更符合实际场景。

**`search_space`**：搜索空间的类型

- `default`：适度的搜索范围，适合通用场景。
- `light`：精简空间，适合快速测试或计算资源受限时使用。
- `comprehensive`：广泛空间，适合充分的计算预算、需要尽可能搜索到最优解时使用。
- 也可为特定集成方式定义专门搜索空间（如 `feature_extraction`、`ensemble`、`end2end`）。

### 评估与日志配置

`EVALUATION_CONFIG` 与 `LOGGING_CONFIG` 分别控制评估指标、可视化和日志记录的行为：

```python
EVALUATION_CONFIG = {
    'metrics': ['mean_error', 'median_error', 'rmse', '75th_percentile', '90th_percentile'],
    'visualizations': ['error_cdf', 'error_distribution', 'error_heatmap', 'error_2d_scatter', 'floor_confusion_matrix'],
    'output_dir': './results',
}

LOGGING_CONFIG = {
    'log_level': 'INFO',                  # 日志级别: 'DEBUG'|'INFO'|'WARNING'|'ERROR'
    'console_output': True,               # 是否在控制台打印日志
    'save_training_history': True,        # 是否保存训练过程历史信息
    'save_predictions': True,             # 是否保存详细预测结果
    'save_parameters': True,              # 是否保存模型参数
    'save_epoch_checkpoints': True,       # 是否按周期保存模型检查点
    'checkpoint_frequency': 10,           # 每隔多少轮保存一次检查点
    'visualization_formats': ['png', 'pdf'], # 生成可视化的文件格式
    'time_encoded_folders': True,         # 是否在输出文件夹名中使用时间戳
}
```

#### 评估配置

**`metrics`**：评估时计算的指标列表

- `mean_error`：平均欧几里得距离误差（最常用的综合指标）。
- `median_error`：误差的中位数，对异常值更不敏感。
- `rmse`：均方根误差，对较大误差有更高的惩罚。
- `75th_percentile`：75 分位误差，可衡量系统对大部分样本的性能。
- `90th_percentile`：90 分位误差，可反映系统在较极端情况下的表现。
- 系统在楼层预测场景下还会自动记录楼层准确率等。

**`visualizations`**：评估时生成的可视化类型

- `error_cdf`：定位误差的累积分布函数。
- `error_distribution`：定位误差直方图。
- `error_heatmap`：在空间分布上显示误差的热力图（若环境信息可用）。
- `error_2d_scatter`：误差的二维散点图，直观查看坐标方向上的偏差。
- `floor_confusion_matrix`：楼层预测的混淆矩阵。

**`output_dir`**：评估结果的输出目录

- 在此目录下保存 JSON 或 CSV 格式的指标、可视化图表等。
- 每个实验会在该目录下新建一个子文件夹，以避免相互覆盖。

#### 日志配置

**`log_level`**：日志详细程度

- `DEBUG`：最详细的日志，包含大量内部信息。
- `INFO`：常规运行信息。
- `WARNING`：潜在问题提示，但不影响程序运行。
- `ERROR`：严重错误提示，通常导致程序无法继续。

**`console_output`**：是否在控制台输出日志

- 若设置为 False，可保持终端整洁，或通过其他方式重定向输出。

**`save_training_history`**：是否保存每个 epoch 的训练历史信息

- 包括损失、指标和学习率等，方便后续可视化和分析。

**`save_predictions`**：是否保存完整预测结果

- 若为 True，则对测试集中的每条样本保存预测坐标、真实坐标、误差等。
- 可用于更细的分析或自定义可视化。

**`save_parameters`**：是否保存最终训练的模型参数配置

- 便于重现同一模型或分享给其他环境部署。

**`save_epoch_checkpoints`**：是否在训练期间定期保存模型

- 便于在训练中途终止或出现故障后恢复，也可分析不同时期的模型状态。

**`checkpoint_frequency`**：每多少轮保存一次模型检查点

- 数值越低，保存越频繁，但磁盘占用也增多。

**`visualization_formats`**：可视化输出格式

- 常见为 `png`（通用）、`pdf`（高质量）。
- 可同时指定多个格式。

**`time_encoded_folders`**：在输出文件夹中是否使用时间戳

- 可防止不同实验的结果互相覆盖。
- 形成按时间顺序排列的目录结构，便于管理和归档。

------

## 模型优化

本节将介绍如何对室内定位系统进行优化以获得最大定位精度。

### 优化策略

#### 1. 使用命令行参数进行快速试验

通过命令行参数，可在不修改配置文件的情况下快速测试不同方案：

```bash
# 对比三种集成方式
python main.py --integration_type feature_extraction --no_optimization
python main.py --integration_type ensemble --no_optimization
python main.py --integration_type end2end --no_optimization
```

上述命令将分别在无需超参优化的情况下测试三种集成方式的默认表现。

```bash
# 测试有无反馈机制
python main.py --with_feedback
python main.py --without_feedback
```

可用于对比自适应反馈机制对定位精度的影响。反馈机制通常能在存在系统偏差或信号变化的情况下带来更大提升。

#### 2. 直接修改配置文件

若需同时调整多个参数或进行持久化的实验设置，可编辑 `config.py` 中的相关值。适合以下场景：

- 需要设置复杂的参数组合
- 修改命令行参数无法覆盖的配置
- 建立固定的实验环境以重复或共享结果

#### 3. 使用 Optuna 的自动化超参数优化

Optuna 能够在指定的搜索空间内自动搜索最优参数组合：

```bash
# 例如运行 200 次试验的优化
python main.py --n_trials 200
```

或在 `config.py` 中直接修改优化设置：

```python
OPTIMIZATION_CONFIG = {
    'n_trials': 200,  # 提高或减少试验次数
    # 其他设置...
}
```

优化过程大致如下：

1. 从 `search_spaces.py` 中初始化搜索空间
2. 采用贝叶斯优化策略随机采样参数组合
3. 对每组参数执行模型训练和交叉验证
4. 提前淘汰（pruning）表现不佳的组合
5. 最终确定最佳参数并更新当前配置

通常，Optuna 对 Transformer 架构或 SVR 参数的搜索能获得显著优于默认配置的效果。提升幅度取决于试验次数和搜索空间范围。

#### 4. 进行系统化的对比试验

系统提供了脚本 `run_experiments.py` 来执行一系列对比性实验：

```bash
# 运行所有对比实验
python run_experiments.py --experiment all

# 分别运行某一类对比
python run_experiments.py --experiment integration
python run_experiments.py --experiment feedback
python run_experiments.py --experiment optimization
```

每种对比实验都会在受控条件下分别测试不同配置，并自动生成可视化图表和对照表，以便深入分析结果差异。

### 参数调优建议

#### SVR 参数调优

在坐标预测任务中，SVR 至关重要，需关注以下关键参数：

- **核函数（kernel）**
  - `rbf`：大多数情况下表现最好，可建模复杂非线性关系
  - `linear`：若数据量大或仅需线性模型时可试用，速度快但精度有限
  - `poly`：对特定多项式关系有优势，但较慢，一般不如 `rbf` 通用
- **C 值**
  - 1~10 范围适合初步尝试
  - 大范围（50~100）可在出现大误差时进一步拟合，但易过拟合
  - 若发现定位误差分布两极分化，可尝试加大 C
- **epsilon**
  - 对于亚米级高精度定位可尝试更小值（0.01~0.05）
  - 对一般米级定位，0.1 较为合适
  - 若对误差不敏感，也可使用更大值（0.5~1.0）提高稳定性
- **gamma（针对 rbf 核）**
  - `scale` 是大多数场景下的稳妥默认值
  - 手动设置时，小值（0.001~~0.01）影响范围更宽，大值（0.1~~1.0）更局部
  - 不当的 gamma 易导致过/欠拟合

#### Transformer 参数调优

Transformer 的表示能力与超参设置高度相关：

- **d_model**（隐藏维度）
  - 64~128：适合小规模数据或快速原型
  - 256~512：更强表达能力，一般室内定位的常用选择
  - 越大越易过拟合，需配合正则化和足够数据
- **nhead**（注意力头数）
  - 与 d_model 必须保持可整除关系
  - 常用 4、8、16（取决于 d_model）
  - 头数增加可学习到更多模式，但计算量随之提升
- **num_layers**（层数）
  - 2~3：轻量快速
  - 4：较常用
  - 6 及以上：适合大数据场景，性能或有提升但训练更难
- **dim_feedforward**（前馈层宽度）
  - 通常为 d_model 的 2~4 倍
  - 可提高到 1024 或以上，但也会增加计算负担
- **dropout**（随机失活率）
  - 0.1 是常见初始值
  - 若过拟合明显，可升至 0.2~0.3
  - 若学习困难，可降至 0.05
- **学习率（lr）**
  - 典型范围为 0.0001~0.001
  - 可考虑调度器以动态调整学习率
  - 训练不稳定时可降低；训练停滞或收敛慢时可适度升高

#### 集成策略选择

恰当的集成方式往往是高精度定位的关键：

- **Feature Extraction（特征提取）**
  - 优点：训练相对简单，资源占用少
  - 缺点：信息可能在中间过程丢失
  - 适用：中等规模数据或较为有限的计算环境
- **Ensemble（集成）**
  - 优点：通常精度最佳，鲁棒性强
  - 缺点：训练和推理时间更长
  - 适用：对精度和鲁棒性要求最高，资源允许的场合
- **End-to-End（端到端）**
  - 优点：可以最充分地利用数据，潜在性能最高
  - 缺点：训练复杂，需大量数据和调参
  - 适用：大规模数据、对性能极致追求且有调参耐心

若计算资源充裕，可首选 `ensemble` 以获取最高平均精度；若想在性能和效率间平衡，可选 `feature_extraction`；若有大量数据并有精力调优，`end2end` 也许可以取得更佳表现。

#### 楼层分类调优

楼层识别的好坏会显著影响整体定位精度：

- **分类器类型**
  - `random_forest`：速度快，准确率高，稳定性好
  - `xgboost`：通常精度更高，但安装与配置略微复杂
  - `svm`：对高维数据有效，但训练速度慢
- **随机森林参数**
  - `n_estimators`：100~200 常见，增大可提高稳定性
  - `max_depth`：可视具体数据量调整，防止过拟合
  - `min_samples_split` / `min_samples_leaf`：增大以减少过拟合
- **特征重要性分析**
  - 训练后可查看哪些 WAP 对楼层判断贡献最大
  - 有助于理解和改进信号覆盖或AP布局

#### 搜索空间自定义

`search_spaces.py` 文件中可定义不同的搜索空间，以针对性地优化：

```python
# 自定义搜索空间示例
CUSTOM_SEARCH_SPACE = {
    'integration_type': ['ensemble'],
    'd_model': [128, 256],
    'nhead': [4, 8],
    'num_layers': [2, 4, 6],
    'kernel': ['rbf'],
    'C': [1.0, 10.0, 100.0],
    # 更多参数...
}
```

在 `get_search_space()` 函数内将自定义的搜索空间加入即可：

```python
def get_search_space(space_type='default'):
    space_types = {
        'default': DEFAULT_SEARCH_SPACE,
        # 其他预定义空间...
        'custom': CUSTOM_SEARCH_SPACE  # 加入自定义空间
    }
    # 余下函数逻辑...
```

然后在配置中使用：

```python
OPTIMIZATION_CONFIG = {
    'search_space': 'custom',
    # 其他设置...
}
```

这可避免对整个大范围参数都进行盲目搜索，更加高效。

### 优化最佳实践

#### 渐进式优化

为高效利用资源，可分阶段进行优化：

1. **初步探索**
   - 使用轻量级搜索空间和较少试验次数（30~50）
   - 先重点考察关键参数（如 integration_type、d_model、kernel）
   - 识别最有潜力的参数区间
2. **参数重要性分析**
   - 利用 Optuna 提供的参数重要性图确定最关键的超参
   - 创建定制搜索空间，聚焦于最重要的参数
3. **集中优化**
   - 在新搜索空间下增加试验次数（100~300）
   - 使用更多折数的交叉验证提高评估可靠性
   - 可在硬件允许时提高并行度
4. **微调**
   - 采用集中优化后的最佳参数作为起点
   - 手动微调那些未纳入自动搜索或对性能有细微影响的次要参数
   - 最终在完整验证集上进行评估

这种分段策略通常比单次大规模搜索更高效，且能逐步收敛到更优解。

#### 性能瓶颈分析

可通过以下途径来定位并改进性能：

1. **学习曲线（Learning Curve）分析**
   - 训练损失 vs. 验证损失是否明显过拟合或欠拟合
   - 若过拟合，考虑增强正则化或缩小模型；若欠拟合，尝试更深层或更高维度
2. **楼层混淆矩阵分析**
   - 找到最易混淆的楼层，或是否存在某一特殊楼层表现异常
3. **误差分布分析**
   - 检查误差是否呈单峰或多峰
   - 长尾现象可能表示极端环境或某些区域信号不足
4. **空间误差模式**
   - 若在某些物理区域误差大，可考虑局部模型或改进 AP 布局

#### 计算资源管理

在优化时需平衡性能与资源：

1. **GPU 显存约束**
   - 若遇到 CUDA out-of-memory 错误，可减小 batch_size、d_model、num_layers
   - 监控训练时的 GPU 占用（nvidia-smi 等）
2. **训练时长控制**
   - 启用早停以避免浪费算力
   - 优先使用较小网络或特征提取模式做初步验证
   - 若需要深入实验，再切换到更大规模模型
3. **优化并行**
   - 调整 n_jobs 以利用多核 CPU
   - 多进程并行会占用额外内存
   - 在多 GPU 环境下可手动并行运行不同实验
4. **渐进式调参**
   - 保留并复用前一次优化的最佳结果作为起点
   - 逐步微调，无需每次都从头探索全部参数空间

------

## 结果解读

运行实验后，系统会在 `./experiments` 目录下生成大量结果文件。每次实验都会新建一个带时间戳的文件夹（例如 `./experiments/feature_extraction_with_feedback_20250506_191730/`），其中包含所有相关输出。

### 目录结构示例

如下是典型的实验输出结构示例：

```
experiments/experiment_name_timestamp/
├── configs/              # 配置文件
│   ├── original/         # 优化前的原始配置
│   ├── optimized/        # 优化后的最佳配置
│   └── by_run/           # 每个独立运行的配置
├── csv_records/          # CSV 格式的记录
│   ├── training/         # 训练过程历史指标
│   ├── evaluation/       # 评估结果
│   └── optimization/     # 优化试验相关记录
├── logs/                 # 日志文件
│   ├── training/         # 训练日志
│   ├── evaluation/       # 评估日志
│   └── optimization/     # 优化日志
├── metrics/              # 评估指标
│   ├── by_epoch/         # 按训练轮次记录的指标
│   ├── by_model/         # 不同模型的指标
│   └── by_config/        # 不同配置的指标
├── models/               # 保存的模型
│   ├── best/             # 最佳模型文件
│   ├── checkpoints/      # 训练过程中的检查点
│   └── final/            # 最终模型文件
├── optuna_results/       # 优化结果
│   ├── best_params/      # 最优参数配置
│   ├── trials/           # 每次试验的具体信息
│   └── visualizations/   # 优化过程的可视化
├── predictions/          # 模型预测结果
│   ├── by_epoch/         # 不同训练轮次的预测
│   ├── final/            # 最终模型的预测
│   └── best/             # 最佳模型的预测
├── results/              # 评估结果汇总
│   ├── comparisons/      # 不同配置间的对比
│   ├── processed/        # 处理后的评估指标
│   └── raw/              # 原始评估数据
└── visualizations/       # 可视化图表
    ├── comparisons/      # 对比分析图
    ├── error_analysis/   # 误差分析图
    └── training/         # 训练过程图
```

该层次化结构便于管理大量实验输出，方便在日后查阅特定文件并进行分析。

### 重要结果文件

以下文件最能体现定位系统的性能与状态：

#### 评估结果

**文件路径**：`results/processed/evaluation_results_*.json`

包含系统性能的全面指标：

- 平均误差（单位：米）
- 中位数误差
- RMSE
- 百分位误差（如 75%、90%）
- 楼层准确率
- 综合误差（如包含楼层惩罚的总误差）
- 分坐标误差（x_mean_error, y_mean_error 等）

**建议分析要点**：

- 若平均误差 < 3m，说明定位效果较好
- 若中位数误差显著小于平均误差，表示存在少量较大误差的离群值
- 楼层准确率若 > 90%，通常可满足多数室内应用
- x、y 误差若差距大，说明模型在某一方向有偏差

#### 详细预测

**文件路径**：`predictions/final/detailed_predictions.csv`

逐条样本的预测信息：

- 真实坐标（longitude, latitude）
- 模型预测坐标
- 每个样本的误差（欧几里得距离）
- 真实楼层与预测楼层
- 楼层预测是否正确
- 建筑物信息（若有）

**用途**：

- 定位高误差样本所在位置，用于环境或模型改进
- 分析在不同建筑或楼层的表现
- 自定义更多可视化或统计指标

#### 训练历史

**文件路径**：`csv_records/training/training_history_*.csv`

记录每轮训练的过程信息：

- 每个 epoch 的损失值
- 验证集损失（若有）
- 学习率
- 时间戳等

**如何使用**：

- 检查训练是否正常收敛
- 是否存在过拟合（训练损失远低于验证损失）
- 估计模型收敛所需的训练轮数
- 判断是否需要调整学习率策略等

#### 最优参数

**文件路径**：`optuna_results/best_params/best_params_*.json`

存储超参数优化后得到的最佳参数：

- 集成方式
- Transformer 结构参数
- SVR 参数
- 楼层分类参数

**作用**：

- 确定哪些参数组合最能提升定位精度
- 为后续实验或生产部署提供参考
- 结合参数重要性分析进一步调优

#### 优化试验记录

**文件路径**：`optuna_results/trials/trial_history_*.json`

包含每次优化试验的详细信息：

- 测试的参数组合
- 对应的性能指标（交叉验证结果）
- 训练时长
- 剪枝（pruning）信息

**意义**：

- 可评估各参数区间对性能的影响
- 分析最优解周边的性能梯度
- 总结资源消耗与性能收益

#### 最佳模型

**文件路径**：`models/best/current_best.pkl`

保存了在验证集上表现最好的模型，可用于：

- 直接做新数据推理
- 检查模型内部结构（若有可视化或调试需求）
- 在新场景或新数据上进行迁移学习
- 发布到生产环境

### 关键可视化文件

系统会生成多种图表以帮助理解模型表现：

#### 学习曲线

**文件路径**：`visualizations/training/learning_curves_*.png`

显示训练和验证损失随 epoch 的变化情况。

**解读**：

- 若训练、验证损失都平稳下降，说明训练健康
- 若训练损失显著低于验证损失，则有过拟合风险
- 若损失曲线早期就平稳，可考虑增大学习率或模型容量
- 若曲线大幅波动，则可能学习率过高

#### 误差分布

**文件路径**：`visualizations/error_analysis/error_distribution_*.png`

展示预测误差在测试集上的分布直方图。

**解读**：

- 越靠近 0 峰值越高说明模型精度越好
- 右尾长则表示有少数非常大的误差
- 若出现多个峰值，可能说明不同区域或场景下信号差异显著

#### 误差 CDF

**文件路径**：`visualizations/error_analysis/error_cdf_*.png`

展示定位误差的累积分布函数（CDF）。

**解读**：

- 曲线攀升越快表示大多数样本误差越小
- 在 y=0.75 处对应的 x 值表示 75% 的样本误差小于该值
- 可以直观比较多条曲线来对比不同模型的优劣
- 曲线越靠左整体表现越好

#### 二维误差散点图

**文件路径**：`visualizations/error_analysis/error_2d_scatter_*.png`

在 x、y 轴上分别绘制预测误差的散点分布。

**解读**：

- 点簇若集中在 (0,0) 附近说明整体偏差小
- 若沿某一轴拉长，说明在该方向上有系统性偏差
- 离群点表示大误差样本
- 有助于诊断模型是否存在方向性失衡

#### 楼层混淆矩阵

**文件路径**：`visualizations/error_analysis/floor_confusion_matrix_*.png`

显示楼层预测的混淆情况。

**解读**：

- 对角线越明显越好，表示正确预测楼层的比例高
- 离对角线越远说明差距越大，可能是信号非常相似或建筑结构的影响
- 若特定两层相互混淆严重，可在数据或模型层面进行有针对性的改进

#### 优化历史

**文件路径**：`optuna_results/visualizations/optimization_history_*.png`

可视化每个试验的优化目标（如误差）随试验次数的变化趋势。

**解读**：

- 趋势向下表示找到更优的参数组合
- 尤其关注最终是否达到平台期或仍在下降
- 大跳跃说明出现大幅改进的参数
- 稳定后可能继续增加试验也难以进一步提升

#### 参数重要性

**文件路径**：`optuna_results/visualizations/param_importances_*.png`

展示每个参数对优化目标影响的大小。

**解读**：

- 越长的条形代表参数越重要
- 可将不重要参数固定，以减少搜索维度并加速优化
- 分析最重要参数在最优解附近是否还有优化空间

#### 参数关系图

**文件路径**：`optuna_results/visualizations/parallel_coordinate_*.png`

平行坐标展示各参数与性能的关系：

**解读**：

- 每条线代表一次试验，颜色代表性能优劣
- 若某些参数组合对应更深色（更优），可在后续集中搜索
- 线条大范围交叉或聚合可揭示参数间的交互作用
- 找到最佳参数附近区域的分布，有助于微调

### 对比实验结果

使用 `run_experiments.py` 进行对比试验后，会额外生成汇总文件和可视化图表：

#### 集成方式对比

**主要文件**：

- `integration_comparison_*/results/comparisons/*.json`
- `integration_comparison_*/visualizations/comparisons/*.png`

展示三种集成策略（feature_extraction、ensemble、end2end）的差异：

- 平均/中位误差对比
- 楼层准确率对比
- 训练时长对比
- 模型大小和推理速度

**常见结论**：

- `ensemble` 通常能带来较小的平均误差，但需更多算力
- `feature_extraction` 速度和资源占用较优
- `end2end` 性能不一定必然超过 `ensemble`，需要更多调参和数据
- 不同场景下最优策略可能不同，需结合资源和需求综合考虑

#### 反馈机制对比

**主要文件**：

- `feedback_comparison_*/results/comparisons/*.json`
- `feedback_comparison_*/visualizations/comparisons/*.png`

用于评估启用反馈机制前后的变化：

- 各种误差指标随时间或样本数量的变化趋势
- 不同误差分位点的对比
- 反馈对特定环境变化的适应情况

**常见结论**：

- 反馈在存在系统性偏差或信号随时间变化时，改进更明显
- 更能降低高误差尾部，对 90%、95% 分位误差帮助较大
- 需要一定量的样本积累才能显现最优效果
- 若环境稳定，反馈收益可能有限

#### 优化规模对比

**主要文件**：

- `optimization_comparison_*/results/comparisons/*.json`
- `optimization_comparison_*/visualizations/comparisons/*.png`

展示不同超参数优化规模（如 50、100、200 次试验）的收敛效果：

- 最终误差差异
- 训练总时长
- 试验间的性能波动

**常见结论**：

- 最初 50~100 次试验会带来显著性能改进
- 超过 200 次后，收益呈现递减趋势
- 对复杂模型而言，更多的试验次数仍可能带来微小但关键的提升
- 是否增加更多试验需权衡时间成本与精度要求

### 绩效指标解读

以下为常见指标的解读方式：

#### 平均误差（Mean Error）

- **单位**：米
- **含义**：预测位置与真实位置的欧几里得距离的平均值
- **解读**：越低越好，最常见的整体定位精度衡量方式
- **建议范围**：若 < 3m，则室内定位结果较好；2m 或更优可视为优秀水准
- **局限性**：易受极端大误差样本的影响

#### 中位数误差（Median Error）

- **单位**：米
- **含义**：所有误差中位数
- **解读**：对异常值更不敏感，反映了“典型”用户体验
- **建议范围**：在 WiFi 定位中通常在 2~4m 之间为理想
- **与平均误差的关系**：若中位数远小于平均数，表示少量大误差在拉高平均值

#### RMSE（Root Mean Square Error）

- **单位**：米
- **含义**：对误差平方取平均后再开方
- **解读**：更强调大误差的影响；在科研和稳健场景中常用
- **建议范围**：在室内定位场景中，如果低于 6m，通常可接受；3~5m 视为较好

#### 75 分位误差（75th Percentile Error）

- **单位**：米
- **含义**：75% 的样本误差低于此值
- **解读**：表示“绝大多数”用户能获得的定位精度
- **建议范围**：若低于 7m，一般能覆盖绝大多数场景

#### 90 分位误差（90th Percentile Error）

- **单位**：米
- **含义**：90% 的样本误差低于此值
- **解读**：接近最糟糕情况下的精度表现，关键场合需关注
- **建议范围**：若低于 10m，说明极端误差也不至于太大

#### 楼层准确率（Floor Accuracy）

- **单位**：百分比
- **含义**：测试样本中预测楼层正确的比例
- **解读**：楼层错误会带来数米的纵向误差惩罚，对用户体验影响明显
- **建议范围**：若超过 90%，在多层建筑中较为可用；95%+ 则相当优秀

#### 综合误差（Combined Error）

- **单位**：米
- **含义**：在二维误差基础上，额外引入楼层误差惩罚（常设每层差 4 米等）
- **解读**：能同时考虑平面误差与楼层误差
- **计算**：2D 误差 + (floor_penalty × floor_error)
- **用途**：楼层错误代价很高时的综合指标

#### X 和 Y 方向误差

- **单位**：米
- **含义**：分别在经度方向和纬度方向的绝对误差
- **解读**：若 x、y 误差差异显著，可能表示建筑结构或信号方向性问题
- **建议**：尽量做到 x、y 误差均衡

------

## 架构分析

本节详细介绍系统的整体架构设计，以及各组件交互和关键设计选择的原因。

### 系统整体架构

该室内定位系统采用分层、多模块的设计，以兼顾灵活性、可扩展性与性能：

```
数据层:    预处理 → 特征工程 → 交叉验证
    ↓
模型层:    SVR + Transformer → 混合集成 → 楼层分类
    ↓
反馈层:    实时调整 → 元自适应 → 在线学习
    ↓
评估层:    误差指标 → 可视化 → 性能分析
```

该层次结构允许每个模块独立开发、测试与改进，同时在层与层之间提供清晰的接口。

### 三种集成架构

系统支持以下三种独立的整合方式，每种都有不同的优劣与适用场景：

#### 1. 特征提取架构

```
                     ┌─────────────────┐
                     │                 │
WiFi Signals ───────►│   Transformer   │──► 特征表示 ───┐
                     │                 │               │
                     └─────────────────┘               ▼
                                                  ┌─────────┐
                                                  │         │
                                                  │   SVR   │──► 位置
                                                  │         │
                                                  └─────────┘
```

**工作原理**：

1. 先输入高维 WiFi 数据到 Transformer 编码器
2. Transformer 通过多层自注意力，输出更具表达力的特征
3. 将此特征喂入 SVR，进行最终二维坐标回归

**实现细节**：

- Transformer 相当于一条固定的特征处理管线
- SVR 负责回归任务，两者间无端到端的反向传播
- 强调表示学习与传统回归的结合

**优点**：

- 结合了 Transformer 的模式提取能力和 SVR 的回归能力
- 训练过程相对简单，资源开销比端到端低
- 在数据中等规模时效果较好

**缺点**：

- 两部分之间信息流动有限，不是真正的联合优化
- 对特征提取后的信息损失无直接纠正

**使用场景**：

- 计算资源有限或希望快速迭代模型
- 中等规模数据集

#### 2. 集成（Ensemble）架构

```
                     ┌─────────────────┐
                     │                 │
WiFi Signals ───────►│   Transformer   │──► 预测1 ──┐
                     │                 │            │
                     └─────────────────┘            ▼
                                              ┌─────────────┐
                                              │   加权平均   │──► 最终位置
                                              └─────────────┘
                     ┌─────────────────┐            ▲
                     │                 │            │
WiFi Signals ───────►│      SVR        │──► 预测2 ──┘
                     │                 │
                     └─────────────────┘
```

**工作原理**：

1. 同一批 WiFi 输入分别送入 Transformer 和 SVR
2. 独立训练并独立输出位置预测
3. 加权平均合并两者的结果
4. 权重可固定也可动态更新

**实现细节**：

- 两个模型彼此独立训练
- 最终阶段才进行预测融合
- 可在反馈机制中动态调整权重

**优点**：

- 利用两种不同模型的互补优势
- 通常获得较高平均精度
- 对单模型异常具有鲁棒性

**缺点**：

- 训练与维护两套完整模型
- 推理时也需执行两次模型计算
- 权重需要额外调参

**使用场景**：

- 对精度要求极高，资源较充足
- 数据具有多样性，不同模型互补

#### 3. 端到端（End-to-End）架构

```
┌───────────────────────────────────────────────────────┐
│                                                       │
│                  ┌─────────────────┐                  │
│                  │    Transformer  │                  │
│   WiFi    ───────►     Encoder     ├────────┐         │
│  Signals         │                 │        │         │
│                  └─────────────────┘        ▼         │
│                                        ┌──────────┐   │
│                                        │  SVR     │   │
│                                        │  Loss    │───► 位置
│                                        │  Layer   │   │
│                                        └──────────┘   │
│                                                       │
└───────────────────────────────────────────────────────┘
                统一模型
```

**工作原理**：

1. WiFi 数据经过 Transformer 提取特征
2. 将特征输入包含 SVR 特性的网络层
3. 通过端到端的反向传播优化所有参数
4. 同时兼顾特征提取与回归任务

**实现细节**：

- 在神经网络中自定义 SVR 样式的损失函数
- 整个管线由同一优化器训练
- 可实现信息无缝流动

**优点**：

- 潜在地可实现更高性能
- 真正的联合训练，捕捉更深层关系
- 只需部署单一模型

**缺点**：

- 训练难度高，对数据和调参要求更高
- 若数据量不足，易过拟合或难收敛
- 模型可解释性较弱

**使用场景**：

- 数据规模较大、对性能要求极致
- 有充足时间和算力进行调优

### 楼层分类与坐标预测

系统采用两阶段预测方法，先确定楼层，再预测该楼层上的坐标：

```
                                                      ┌─────────────┐
                                                 ┌───►│   楼层分类   │──► 楼层号
                                                 │    └─────────────┘
                                                 │
┌──────────────┐    ┌─────────────────┐         │
│              │    │                 │         │
│ WiFi Signals │───►│  预处理         │─────────┤
│              │    │                 │         │
└──────────────┘    └─────────────────┘         │
                                                 │    ┌─────────────┐
                                                 │    │ 坐标预测    │
                                                 └───►│ (x, y)回归  │──► (x,y)
                                                      └─────────────┘
```

**分开处理的原因**：

1. **差异化任务类型**：楼层预测是分类任务，坐标预测是回归任务，各自的算法和超参需求不同。
2. **误差影响大**：楼层预测错误会带来严重的纵向偏差，用独立分类器可提高楼层识别的精度。
3. **信号特征差异**：一些特征对于区分楼层很重要，但对细致坐标预测影响较小。分开后可针对性优化。
4. **灵活性**：可独立更换或调整楼层分类与坐标回归的模型。
5. **层级思路**：与人类在建筑内先确认楼层再找具体位置的过程类似，更符合物理逻辑。

**实现细节**：

- 楼层分类可用 Random Forest、XGBoost 或 SVM
- 坐标回归可由 SVR、Transformer、或二者混合
- 在最终误差中综合考虑楼层差误差（如每层 3~4m）

### 双层反馈机制

系统还实现了双层反馈机制，以在运行中持续提升定位效果：

```
              ┌─────────────────────────────────────────────┐
              │                                             │
              │           高层反馈 (Meta-adaptation)         │
              │      (更慢的更新周期, 战略层调整)            │
              │                                             │
              └───────────────────┬─────────────────────────┘
                                  │
                                  │ 调整学习参数
                                  │
                                  ▼
┌─────────────┐    ┌─────────────────────────────────────────────┐    ┌──────────────┐
│             │    │                                             │    │              │
│ 预测结果    │───►│           底层反馈 (Immediate)              │───►│   更新后     │
│             │    │  (快速响应, 直接修正近期误差)              │    │ 预测结果     │
│             │    │                                             │    │              │
└─────────────┘    └─────────────────────────────────────────────┘    └──────────────┘
```

#### 底层反馈（Lower-Level Feedback）

提供针对即时误差的快速调整：

- **主要特征**：
  - **快速反应**：在每次预测后立刻根据误差进行局部修正
  - **较大学习率**：通常在 0.01 左右以便及时适应
  - **局部适应**：解决当前区域或时间段的特定偏差
  - **实现**：可通过直接调整模型参数或在集成模式下动态加权
- **优点**：
  - 能快速纠正短期误差
  - 在环境噪声或小范围变化时效果明显
  - 适合随时微调

#### 高层反馈（Higher-Level Feedback / Meta-adaptation）

在较长时间跨度上进行元学习：

- **主要特征**：
  - **策略层**：分析长期误差模式，并对底层反馈策略做调整
  - **较小学习率**：一般在 0.001 用于平稳学习
  - **长窗口**：如 100 个样本的误差记录，避免短期抖动
  - **实现**：动态调节底层反馈的学习率或更新策略
- **优点**：
  - 纠正底层反馈可能的过度拟合
  - 适应更大范围的环境变化，如信道衰减或 AP 重部署
  - 长期累积可实现系统性改进

双层反馈相结合，既能快速响应近期误差，又能从整体上校正策略，使系统在不断变化的环境中长期保持较好性能。

------

## 优化流程

本节详细说明如何使用系统提供的超参数优化框架，以及如何配置、执行并分析优化结果。

### Optuna 优化框架

系统依托 Optuna 实现自动化的超参数搜索：

```
┌───────────────────────────────────────────────────────────────────────┐
│                          Optuna 框架                                 │
│                                                                        │
│   ┌────────────────┐                               ┌──────────────┐    │
│   │                │                               │              │    │
│   │ 搜索空间定义   │───┐                      ┌───►│ 最优参数     │    │
│   │                │   │                      │    │              │    │
│   └────────────────┘   │                      │    └──────────────┘    │
│                        ▼                      │                        │
│                   ┌────────────┐        ┌─────────────┐                │
│                   │            │        │             │                │
│                   │ 参数采样   │◄───────┤ 剪枝机制    │                │
│   ┌─────────────┐ │            │        │             │ ┌────────────┐ │
│   │             │ └────────────┘        └─────────────┘ │            │ │
│   │ 目标函数     │        │                    ▲         │ Study 数据 │ │
│   │ (Objective) │        ▼                    │         │ 库          │ │
│   │             │ ┌────────────┐        ┌─────────────┐ └────────────┘ │
│   └─────────────┘ │ 试验评估   │───────►│ 性能指标     │        ▲        │
│         ▲         │ (Trial)     │        │ (Metrics)   │        │        │
│         │         └────────────┘        └─────────────┘        │        │
│         └─────────┤                                              │        │
│                   │                                              │        │
└───────────────────────────────────────────────────────────────────────┘
```

#### 关键组件

1. **搜索空间定义（Search Space）**
   - 指定可调参数及其取值范围
   - 位于 `search_spaces.py`，可自定义或使用预置的 default、light、comprehensive
2. **目标函数（Objective Function）**
   - 训练并评估模型，返回性能指标（如误差）
   - 在 `optuna_optimizer.py` 中实现
   - 通常通过交叉验证来获得稳健评估
3. **参数采样（Parameter Sampling）**
   - Optuna 使用 TPE 等算法从搜索空间中有策略地采样
   - 结合历史试验结果，平衡探索与开发（exploitation）
4. **试验评估（Trial Evaluation）**
   - 对每组采样参数进行完整训练/验证
   - 计算误差或准确率作为反馈
   - 若性能不佳，可被提前剪枝
5. **剪枝机制（Pruning）**
   - 通过中期结果预测最终表现，提前停止不佳试验
   - 减少无效计算，节省大量时间
6. **Study 数据库**
   - 记录所有试验的参数、评估结果
   - 支持可视化与事后分析
   - 可持久化保存，便于断点续跑

#### Optuna 工作原理

1. **初始化**
   - 根据 `search_spaces.py` 建立搜索空间
   - 创建 Study，设定剪枝策略（如 `MedianPruner`）
   - 指定优化方向（如 `minimize` 表示降低误差）
2. **循环试验**
   - 逐个采样参数
   - 进行交叉验证，得到性能指标
   - 记录结果并更新优化方向
   - 应用剪枝以停止低效试验
3. **结果输出**
   - 找到最佳参数
   - 保存到 `optuna_results/best_params/`
   - 生成可视化（如参数重要性、平行坐标、优化历史等）

### 优化工作流

完整流程如下：

1. **初始化**
   - 从 `config.py` 读取默认配置
   - 选择搜索空间（如 `default`、`light`）
   - 建立 Optuna Study 并启用剪枝
   - 将方向设为 `'minimize'`（针对误差）
2. **数据准备**
   - 加载并预处理数据
   - 设定交叉验证方式（如 spatial CV）
   - 准备评估指标和回调
3. **试验循环**
   - 对每次试验，抽取一组参数
   - 根据参数实例化模型组件（如 SVR、Transformer）
   - 执行交叉验证训练与评估
   - 计算性能（如平均误差）
   - 报告给 Optuna，并检查是否需要剪枝
4. **结果处理**
   - 找出最优参数
   - 更新并保存配置
   - 记录并可视化所有试验结果
   - 输出相关图表与日志
5. **最终模型训练**
   - 用最佳参数训练楼层分类器与定位模型
   - 若启用反馈机制，则一并配置
   - 在验证集/测试集上评估并输出最终结果

### 自定义优化目标

系统默认使用一个综合目标，将坐标误差与楼层准确率综合在一起：

```python
# 伪代码示例
def objective(trial):
    # 从搜索空间中获取参数
    params = _suggest_params(trial)
    
    # 创建模型
    floor_classifier = FloorClassifier(**params)
    position_model = SVRTransformerHybrid(**params)
    
    # 交叉验证结果
    cv_coords_scores = []
    cv_floor_scores = []
    
    # 逐折训练与验证
    for train_idx, test_idx in cv_splitter.split(X, y):
        # 训练
        floor_classifier.fit(X[train_idx], y_floor[train_idx])
        position_model.fit(X[train_idx], y_coords[train_idx])
        
        # 预测
        coords_pred = position_model.predict(X[test_idx])
        floor_pred = floor_classifier.predict(X[test_idx])
        
        # 计算指标
        coords_error = mean_euclidean_error(y_coords[test_idx], coords_pred)
        floor_accuracy = np.mean(y_floor[test_idx] == floor_pred)
        
        cv_coords_scores.append(coords_error)
        cv_floor_scores.append(floor_accuracy)
        
        # 报告中间结果以支持剪枝
        trial.report(coords_error, fold_idx)
        if trial.should_prune():
            raise optuna.exceptions.TrialPruned()
    
    # 计算平均指标
    mean_coords_error = np.mean(cv_coords_scores)
    mean_floor_accuracy = np.mean(cv_floor_scores)
    
    # 将楼层准确率以一定权重加入目标中
    floor_weight = 5.0
    combined_score = mean_coords_error - mean_floor_accuracy * floor_weight
    
    return combined_score
```

**关键点**：

- 通过加权将楼层准确率纳入目标
- 使用交叉验证得出更稳定的评估
- 中途剪枝可节省时间
- `floor_weight` 可调大或调小，以侧重楼层准确率或坐标精度
- 最终返回越低越好的目标值（故将准确率带负号）

若希望单独最小化坐标误差或最大化楼层准确率，可相应地调整目标函数。或使用其他多目标方法（如约束优化、分阶段优化等）。

### 可视化与结果分析

完成优化后，系统会生成多个可视化文件，以便理解与诊断优化过程：

#### 1. 优化历史图

**路径**：`optuna_results/visualizations/optimization_history_*.png`

- x 轴为试验次数
- y 轴为目标函数值
- 趋势向下表示找到更优参数
- 观察是否在某处出现平台期

#### 2. 参数重要性图

**路径**：`optuna_results/visualizations/param_importances_*.png`

- 纵向列出最主要的参数
- 条形长度代表对最终性能的影响程度
- 便于下一步专注于重要参数并简化不重要的参量

#### 3. 平行坐标图

**路径**：`optuna_results/visualizations/parallel_coordinate_*.png`

- 每个竖轴代表一个参数或目标
- 不同颜色表示性能差异
- 寻找颜色更优的线条所对应的参数组合

#### 4. 等高线图（Contour Plots）

**路径**：`optuna_results/visualizations/contour_*.png`

- 展示最重要的两个或多个参数与目标之间的关系
- 颜色深浅或曲线表示性能高低
- 帮助发现最优区域或局部极值

### 高效优化策略

要充分利用该优化框架，可考虑以下建议：

#### 1. 渐进式精细化

避免一次性大范围随机搜索，而是分阶段缩小范围：

```
阶段1: 粗略探索
- 使用简化搜索空间 (light)
- 试验次数 30~50
- 识别最优或较优区域

阶段2: 聚焦搜索
- 自定义搜索空间, 聚焦关键参数
- 试验次数 50~100
- 更高折数交叉验证

阶段3: 精细微调
- 更窄的搜索范围
- 试验次数 50~100
- 专注发掘局部最优
```

这种方法往往比一次大规模搜索更高效、易收敛。

#### 2. 复用历史优化结果（Warm Start）

可将之前找到的最优参数当作新搜索的起点：

```python
previous_best = {
    'integration_type': 'ensemble',
    'd_model': 256,
    'nhead': 8,
    'C': 10.0,
    # 其他参数...
}

# 在新的搜索空间中重点围绕 previous_best 附近
custom_search_space = {
    'integration_type': ['ensemble'],
    'd_model': [128, 256, 512],
    'nhead': [4, 8, 16],
    'C': [1.0, 10.0, 100.0],
    # ...
}
```

能明显加快收敛进度。

#### 3. 多目标平衡

可使用多种方法在多目标间（坐标误差与楼层准确率）进行折中：

```python
# 方法1: 加权组合 (系统默认)
combined_score = position_error_weight * mean_position_error - \
                floor_accuracy_weight * floor_accuracy

# 方法2: 约束式优化
if floor_accuracy < minimum_acceptable_accuracy:
    return float('inf')  # 不符合楼层准确率要求则丢弃
else:
    return mean_position_error
```

#### 4. 剪枝配置

好的剪枝参数能显著降低优化时间：

```python
pruner = optuna.pruners.MedianPruner(
    n_startup_trials=5,  # 前几次试验不剪枝
    n_warmup_steps=2,    # 每个试验前2个迭代不剪枝
    interval_steps=1     # 每个迭代都进行剪枝判断
)

study = optuna.create_study(pruner=pruner, direction='minimize')
```

需注意平衡剪枝阈值，避免过早丢弃潜在好参数。

------

## 故障排查

本节罗列在使用室内定位系统时常见的问题，并给出解决思路。

### 安装与环境问题

#### 模块导入错误

**现象**：

```
ModuleNotFoundError: No module named 'xxx'
```

**可能原因**：

- 未安装所需的 Python 包
- 在错误的工作目录下运行
- 包安装在不同的虚拟环境中
- 拼写错误

**解决方案**：

1. **安装缺失依赖**：

   ```bash
   pip install numpy pandas scikit-learn torch matplotlib seaborn optuna
   pip install xgboost
   ```

2. **检查工作目录**：

   ```bash
   cd /path/to/project/root
   python main.py
   ```

3. **检查 Python 环境**：

   ```bash
   # 激活虚拟环境
   source /path/to/venv/bin/activate  # Linux/Mac
   # 或
   \path\to\venv\Scripts\activate     # Windows
   
   # 查看已安装包
   pip list
   ```

4. **核对 import 语句**：

   ```python
   from data.loader import UJIIndoorLocLoader
   from models.hybrid_model import SVRTransformerHybrid
   ```

#### CUDA/GPU 相关错误

**现象**：

```
RuntimeError: CUDA error: device-side assert triggered
```

或

```
CUDA out of memory. Tried to allocate X.XX GiB
```

**可能原因**：

- CUDA 与 PyTorch 版本不匹配
- GPU 显存不足
- 模型或张量操作无效
- 设备不一致（某些张量在 CPU 上，某些在 GPU 上）

**解决方案**：

1. **确认 CUDA 与 PyTorch 兼容性**：

   ```bash
   python -c "import torch; print(torch.__version__, torch.version.cuda)"
   ```

   根据 [pytorch.org](https://pytorch.org/get-started/locally/) 上的指引重新安装正确版本。

2. **减小批大小**：

   ```python
   'transformer': {
       'batch_size': 32,  # 原为64可尝试降为32
   }
   ```

3. **减小模型规模**：

   ```python
   'transformer': {
       'd_model': 128,
       'num_layers': 2,
       # ...
   }
   ```

4. **强制 CPU**（若调试或资源有限）：

   ```python
   MODEL_CONFIG = {
       'device': 'cpu',
       # ...
   }
   ```

5. **监控 GPU**： 使用 `nvidia-smi` 工具查看显存占用情况。

#### 数据加载问题

**现象**：

```
FileNotFoundError: [Errno 2] No such file or directory: './data/raw/TrainingData.csv'
```

**可能原因**：

- 未下载或放置数据集
- `data_dir` 路径错误
- 无权限读取
- 自动下载过程中网络出错

**解决方案**：

1. **启用自动下载**：

   ```python
   DATA_CONFIG = {
       'data_dir': './data/raw',
       'download': True,
       # ...
   }
   ```

2. **手动下载**：

   ```bash
   mkdir -p ./data/raw
   cd ./data/raw
   wget https://archive.ics.uci.edu/ml/machine-learning-databases/00310/UJIndoorLoc.zip
   unzip UJIndoorLoc.zip
   ```

3. **权限检查**：

   ```bash
   chmod -R 755 ./data
   ```

4. **目录结构**： 确保 `TrainingData.csv` 和 `ValidationData.csv` 位于 `./data/raw/` 下。

### 模型训练问题

#### Transformer 维度错误

**现象**：

```
AssertionError: embed_dim must be divisible by num_heads
```

**可能原因**：

- `d_model` 与 `nhead` 不匹配
- 搜索空间中存在不兼容的组合

**解决方案**：

1. **手动修正**：

   ```python
   'transformer': {
       'd_model': 256,
       'nhead': 8,
       # ...
   }
   ```

2. **常见可行组合**：

   - d_model=64, nhead=2,4,8
   - d_model=128, nhead=4,8,16
   - d_model=256, nhead=4,8,16

3. **在搜索空间中排除无效组合**。

#### 训练不收敛

**现象**：损失值不下降或下降极慢

**可能原因**：

- 学习率不当
- 初始化或数据存在问题
- 模型不适合此数据
- 预处理不合理

**解决方案**：

1. **调整学习率**：

   ```python
   'transformer': {
       'lr': 0.0005,  # 原 0.001 可尝试上下调
   }
   ```

2. **数据归一化**：

   ```python
   DATA_CONFIG = {
       'normalization': 'standard',
       # ...
   }
   ```

3. **查看学习曲线**： 检查 `visualizations/training/learning_curves_*.png`，判断是否过拟合、欠拟合或震荡。

4. **简化模型**： 从 `feature_extraction` 或较小网络开始。

5. **梯度裁剪**（需要在代码中添加）：

   ```python
   torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
   ```

#### 过拟合

**现象**：训练集误差低但验证集误差高

**可能原因**：

- 模型容量过大
- 正则化不足
- 训练轮数过多
- 数据泄漏

**解决方案**：

1. **增加 Dropout**：

   ```python
   'transformer': {
       'dropout': 0.2,
   }
   ```

2. **减小模型规模**：

   ```python
   'transformer': {
       'd_model': 128,
       'num_layers': 2,
   }
   ```

3. **启用早停**：

   ```python
   'early_stopping': {
       'enabled': True,
       'patience': 10,
       # ...
   }
   ```

4. **使用空间交叉验证**：

   ```python
   OPTIMIZATION_CONFIG = {
       'cv_method': 'spatial',
       # ...
   }
   ```

5. **加大 SVR 正则化**：

   ```python
   'svr': {
       'C': 1.0,
       # ...
   }
   ```

### 性能和评估问题

#### 楼层分类效果差

**现象**：楼层预测不准确，坐标却相对准确

**可能原因**：

- 分类特征不足
- 选择的分类器不合适
- 数据集中某些楼层样本过少
- 楼层信号差别不明显

**解决方案**：

1. **更换分类器**：

   ```python
   'floor_classifier': {
       'type': 'xgboost',
       # ...
   }
   ```

2. **调整分类器参数**：

   ```python
   'floor_classifier': {
       'type': 'random_forest',
       'n_estimators': 200,
       'max_depth': 15,
       # ...
   }
   ```

3. **查看混淆矩阵**： 分析错误集中在哪些楼层。

4. **楼层特征选取**： 可能通过 PCA 之外的方法专门筛选对楼层区分度高的特征。

5. **对难分楼层单独微调**。

#### 定位误差大

**现象**：整体误差偏高

**可能原因**：

- 模型容量不足
- 特征或数据质量差
- 集成方式不匹配
- 未充分进行超参优化

**解决方案**：

1. **尝试不同集成方式**：

   ```bash
   python main.py --integration_type ensemble
   ```

2. **增大模型规模**：

   ```python
   'transformer': {
       'd_model': 512,
       'num_layers': 6,
       'dim_feedforward': 1024,
   }
   ```

3. **更多超参优化**：

   ```bash
   python main.py --n_trials 300 --integration_type ensemble
   ```

4. **分析误差分布**：

   - `visualizations/error_analysis/error_distribution_*.png`
   - `visualizations/error_analysis/error_2d_scatter_*.png`

5. **启用反馈机制**：

   ```python
   'feedback': {
       'enabled': True,
       # ...
   }
   ```

#### 多次运行结果不稳定

**现象**：同一配置多次运行，结果差异大

**可能原因**：

- 随机初始化差异
- 训练过程含随机操作
- GPU 并行不确定性
- 优化过程本身有随机性

**解决方案**：

1. **固定随机种子**：

   ```python
   CONFIG = {
       'random_state': 42,
       # ...
   }
   ```

2. **启用确定性**（需要在代码中设置）：

   ```python
   import torch
   torch.backends.cudnn.deterministic = True
   torch.backends.cudnn.benchmark = False
   ```

3. **多次运行取平均**：

   ```bash
   for seed in 42 43 44 45 46; do
       python main.py --random_state $seed
   done
   ```

4. **模型集成**： 可以训练多种随机种子下的模型，然后取平均预测。

5. **固定优化起点**： 从已知较好参数开始，减少随机搜索的波动。

### 优化相关问题

#### 优化耗时太久

**现象**：超参搜索耗费数小时或更久

**可能原因**：

- `n_trials` 设置过大
- 搜索空间范围过宽
- 剪枝设置不完善
- 交叉验证折数多
- 并行度低

**解决方案**：

1. **减少试验次数**：

   ```python
   OPTIMIZATION_CONFIG = {
       'n_trials': 100,
       # ...
   }
   ```

2. **使用轻量搜索空间**：

   ```python
   OPTIMIZATION_CONFIG = {
       'search_space': 'light',
       # ...
   }
   ```

3. **启用并行**：

   ```python
   OPTIMIZATION_CONFIG = {
       'n_jobs': 4,
       # ...
   }
   ```

4. **优化剪枝**：

   ```python
   study = optuna.create_study(
       pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),
       direction='minimize'
   )
   ```

5. **减少 CV 折数**：

   ```python
   OPTIMIZATION_CONFIG = {
       'cv': 3,
       # ...
   }
   ```

#### 优化效果不明显

**现象**：自动搜索后性能与默认类似

**可能原因**：

- 搜索空间过窄
- 局部最优陷阱
- 试验次数不足
- 目标函数噪声大
- 优化算法局限

**解决方案**：

1. **扩大搜索范围**：

   ```python
   OPTIMIZATION_CONFIG = {
       'search_space': 'comprehensive',
       # ...
   }
   ```

2. **增加试验次数**：

   ```python
   OPTIMIZATION_CONFIG = {
       'n_trials': 300,
       # ...
   }
   ```

3. **查看参数重要性**： 若重要参数范围太小，可手动放宽。

4. **分阶段二次优化**： 分次缩窄范围并重新搜索。

5. **调整目标函数**： 如加大楼层权重或改变误差度量方式。

#### Optuna 数据库错误

**现象**：Optuna 内部数据报错，如数据库锁或损坏

**可能原因**：

- 并行多进程同时写 SQLite
- SQLite 文件损坏
- 权限或磁盘空间不足
- 旧数据库兼容性问题

**解决方案**：

1. **使用内存数据库**：

   ```python
   study = optuna.create_study(storage="sqlite:///:memory:", direction='minimize')
   ```

2. **删除旧数据库**：

   ```bash
   rm -f .optuna_studies/*.db
   ```

3. **检查磁盘空间**：

   ```bash
   df -h .
   ```

4. **使用唯一Study名称**：

   ```python
   study_name = f"positioning_study_{int(time.time())}"
   study = optuna.create_study(study_name=study_name, direction='minimize')
   ```

### 可视化与结果问题

#### 可视化文件缺失

**现象**：没有生成预期的图表

**可能原因**：

- Matplotlib 后端设置问题
- 输出目录不存在或无写权限
- 代码中可视化调用异常
- 配置中未开启可视化

**解决方案**：

1. **检查 matplotlib 后端**：

   ```python
   import matplotlib
   matplotlib.use('Agg')  # 在无GUI环境下使用非交互后端
   ```

2. **确认可视化格式**：

   ```python
   LOGGING_CONFIG = {
       'visualization_formats': ['png'],
       # ...
   }
   ```

3. **手动创建目录**：

   ```bash
   mkdir -p ./experiments/latest/visualizations/error_analysis
   ```

4. **权限检查**：

   ```bash
   chmod -R 755 ./experiments
   ```

5. **在代码中加调试信息**，确认可视化函数是否被调用。

#### 无法打开或读取结果文件

**现象**：JSON、CSV 或 pickle 文件无法正常打开

**可能原因**：

- 文件格式被破坏
- 文件过大，加载方式不当
- 文件编码不兼容
- 写入中断导致不完整

**解决方案**：

1. **使用正确工具**：

   - JSON 文件：文本编辑器或 JSON 解析器
   - CSV 文件：Excel、Pandas 等
   - pickle 文件：Python `pickle` 模块
   - 图片文件：查看器或浏览器

2. **验证 JSON**：

   ```bash
   python -m json.tool path/to/result.json > /dev/null
   ```

3. **读取大 CSV**：

   ```python
   import pandas as pd
   df = pd.read_csv('path/to/large_result.csv', nrows=1000)
   ```

4. **查看 README**： 每个实验目录通常包含简要说明文件。

5. **版本管理**： 文件可能以 `file_v1.json, file_v2.json` 等版本形式存储，查看最新版本。

------

通过以上详尽的排查指引，您应能解决在室内定位系统中遇到的大多数常见问题。若仍未能解决，可在 `logs/` 目录下查看更详细的日志信息，或回顾系统的原始文档寻求进一步帮助。

------

